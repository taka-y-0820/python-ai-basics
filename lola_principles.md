## LoRA (Low-Rank Adaptation) の原理

LoRA は、フルファインチューニングとほぼ同等の性能を、**極めて少ない計算リソース**で実現するための、効率的な学習手法（PEFT: Parameter-Efficient Fine-Tuning）です。

### 1. 核心となる数学的仮定: 低ランク近似

LoRA の基盤となるのは、**「大規模言語モデル（LLM）を新しいタスクに特化させるために必要な重みの更新量 ($\Delta W$) は、元の重み行列 $W$ の次元に比べて、遥かに小さな情報量（低ランク）で表現できる」**という仮定です。

- **元の重み行列**: サイズ $d \times k$ の巨大な行列 $W$ （例: $1000 \times 1000$）。フルチューニングでは $d \times k$ 個のパラメータを学習。
- **低ランク近似**: LoRA は、更新行列 $\Delta W$ を、2 つの小さな行列 $A$ と $B$ の積で近似します。
  $$\Delta W \approx B A$$

### 2. パラメータ削減のメカニズム

削減の理由は、**行列の乗算の性質**を活かして、学習対象を元の $W$ から $A$ と $B$ に移すからです。

- **ランク ($r$) の導入**: $r$ は**ランク（階数）**と呼ばれ、元の次元 $d, k$ よりも非常に小さな値（通常 $r=4$ や $r=8$）に設定されます。
- **行列のサイズ**:
  - 行列 $A$: $d \times r$
  - 行列 $B$: $r \times k$
- **学習対象のパラメータ数**:
  - 元の $W$ の学習パラメータ数: $d \times k$
  - LoRA の学習パラメータ数: $(d \times r) + (r \times k)$

**例**: $W$ が $1000 \times 1000$、ランク $r=10$ の場合、学習パラメータ数は $1,000,000$ 個から $20,000$ 個へと**約 98%削減**されます。

### 3. 実行時の仕組み

1.  **重みの固定**: 元の学習済み重み行列 $W$ は凍結（フリーズ）され、変更されません。
2.  **更新の追加**: 学習時には、新しい小さな行列 $A$ と $B$ のパラメータのみが更新されます。
3.  **推論時の結合**: 推論時には、学習済みの $B$ と $A$ を結合し、$\Delta W$ を元の $W$ に加算して使用されます ($W' = W + BA$)。

このメカニズムにより、**GPU メモリの消費を大幅に抑え**、低コストのクラウド環境でも大規模モデルのファインチューニングが可能となります。
